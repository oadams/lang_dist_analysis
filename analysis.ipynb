{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Italian']\n",
      "['French']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oadams/.pyenv/versions/3.11.6/envs/sigtyp/lib/python3.11/site-packages/speechbrain/dataio/encoder.py:722: UserWarning: CategoricalEncoder.expect_len was never called: assuming category count of 45 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/lang-id-commonlanguage_ecapa\", savedir=\"pretrained_models/lang-id-commonlanguage_ecapa\")\n",
    "# Italian Example\n",
    "out_prob, score, index, text_lab = classifier.classify_file('speechbrain/lang-id-commonlanguage_ecapa/example-it.wav')\n",
    "print(text_lab)\n",
    "\n",
    "# French Example\n",
    "out_prob, score, index, text_lab = classifier.classify_file('speechbrain/lang-id-commonlanguage_ecapa/example-fr.wav')\n",
    "print(text_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lang2vec.lang2vec as l2v\n",
    "features = l2v.get_features(\"eng\", \"geo\")\n",
    "features[\"eng\"]\n",
    "l2v.distance(\"syntactic\", \"eng\", \"fra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 1263.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sakha\n",
      "torch.Size([192])\n",
      "Dhivehi\n",
      "torch.Size([192])\n",
      "Dutch\n",
      "torch.Size([192])\n",
      "Interlingua\n",
      "torch.Size([192])\n",
      "Breton\n",
      "torch.Size([192])\n",
      "Czech\n",
      "torch.Size([192])\n",
      "Esperanto\n",
      "torch.Size([192])\n",
      "Catalan\n",
      "torch.Size([192])\n",
      "Latvian\n",
      "torch.Size([192])\n",
      "Japanese\n",
      "torch.Size([192])\n",
      "German\n",
      "torch.Size([192])\n",
      "Estonian\n",
      "torch.Size([192])\n",
      "Chinese_Taiwan\n",
      "torch.Size([192])\n",
      "Tatar\n",
      "torch.Size([192])\n",
      "Kinyarwanda\n",
      "torch.Size([192])\n",
      "Frisian\n",
      "torch.Size([192])\n",
      "Welsh\n",
      "torch.Size([192])\n",
      "Hakha_Chin\n",
      "torch.Size([192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "langs = []\n",
    "embs = []\n",
    "for path in tqdm.tqdm(list(Path('common_voice_kpd').glob('*'))[:18]):\n",
    "    langs.append(path.name)\n",
    "    print(path.name)\n",
    "    emb = torch.load(f'lang_embs/{path.name}_test_emb.pt')\n",
    "    emb = emb.squeeze(1).mean(0)\n",
    "    embs.append(emb)\n",
    "    print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.stack(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.nn.functional.normalize(embs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.2107,  0.0737,  0.2169,  0.1690,  0.0574,  0.1231,  0.0924,\n",
       "          0.0648,  0.0909,  0.1546,  0.2940,  0.1050,  0.5703,  0.1036,  0.1521,\n",
       "          0.2081,  0.2013],\n",
       "        [ 0.2107,  1.0000,  0.0932,  0.1489,  0.2433, -0.0682,  0.1810,  0.0422,\n",
       "          0.0322,  0.2441,  0.0943,  0.1621,  0.1060, -0.0451,  0.0982,  0.0528,\n",
       "          0.0351,  0.0866],\n",
       "        [ 0.0737,  0.0932,  1.0000,  0.1454,  0.1286,  0.0507,  0.0611,  0.1267,\n",
       "          0.1156,  0.0236, -0.0714,  0.0739,  0.0321, -0.0377,  0.1375,  0.5368,\n",
       "          0.0079,  0.0849],\n",
       "        [ 0.2169,  0.1489,  0.1454,  1.0000,  0.2834,  0.0480,  0.5383,  0.4475,\n",
       "          0.2274,  0.2292,  0.1214,  0.4268,  0.2903,  0.0963,  0.2392,  0.2694,\n",
       "          0.2068,  0.1540],\n",
       "        [ 0.1690,  0.2433,  0.1286,  0.2834,  1.0000,  0.0512,  0.2824,  0.2721,\n",
       "          0.2256,  0.1379,  0.2641,  0.3470,  0.1003,  0.2416,  0.3414,  0.1580,\n",
       "          0.2352,  0.1408],\n",
       "        [ 0.0574, -0.0682,  0.0507,  0.0480,  0.0512,  1.0000,  0.1121,  0.1166,\n",
       "          0.1957, -0.0904, -0.0044,  0.0207, -0.0518, -0.0565,  0.0585,  0.0141,\n",
       "          0.1195,  0.0203],\n",
       "        [ 0.1231,  0.1810,  0.0611,  0.5383,  0.2824,  0.1121,  1.0000,  0.2391,\n",
       "          0.2198,  0.2402,  0.1826,  0.1989,  0.0689,  0.0282,  0.1149,  0.0887,\n",
       "          0.1745,  0.2684],\n",
       "        [ 0.0924,  0.0422,  0.1267,  0.4475,  0.2721,  0.1166,  0.2391,  1.0000,\n",
       "          0.2115,  0.0503,  0.1059,  0.3017,  0.1925,  0.1873,  0.1276,  0.1934,\n",
       "          0.2230,  0.1526],\n",
       "        [ 0.0648,  0.0322,  0.1156,  0.2274,  0.2256,  0.1957,  0.2198,  0.2115,\n",
       "          1.0000,  0.0120,  0.0695,  0.1998,  0.0304,  0.1309,  0.1863,  0.2060,\n",
       "          0.0884, -0.0106],\n",
       "        [ 0.0909,  0.2441,  0.0236,  0.2292,  0.1379, -0.0904,  0.2402,  0.0503,\n",
       "          0.0120,  1.0000,  0.0622,  0.1258,  0.1236,  0.0046,  0.0385, -0.0743,\n",
       "          0.0399,  0.3723],\n",
       "        [ 0.1546,  0.0943, -0.0714,  0.1214,  0.2641, -0.0044,  0.1826,  0.1059,\n",
       "          0.0695,  0.0622,  1.0000,  0.0590,  0.1568,  0.1089,  0.0530, -0.0123,\n",
       "          0.1288,  0.1918],\n",
       "        [ 0.2940,  0.1621,  0.0739,  0.4268,  0.3470,  0.0207,  0.1989,  0.3017,\n",
       "          0.1998,  0.1258,  0.0590,  1.0000,  0.2323,  0.2607,  0.1142,  0.1717,\n",
       "          0.1394,  0.0583],\n",
       "        [ 0.1050,  0.1060,  0.0321,  0.2903,  0.1003, -0.0518,  0.0689,  0.1925,\n",
       "          0.0304,  0.1236,  0.1568,  0.2323,  1.0000,  0.0299,  0.0996,  0.0499,\n",
       "          0.1086,  0.1404],\n",
       "        [ 0.5703, -0.0451, -0.0377,  0.0963,  0.2416, -0.0565,  0.0282,  0.1873,\n",
       "          0.1309,  0.0046,  0.1089,  0.2607,  0.0299,  1.0000,  0.0020,  0.1655,\n",
       "          0.1231,  0.0543],\n",
       "        [ 0.1036,  0.0982,  0.1375,  0.2392,  0.3414,  0.0585,  0.1149,  0.1276,\n",
       "          0.1863,  0.0385,  0.0530,  0.1142,  0.0996,  0.0020,  1.0000,  0.0533,\n",
       "          0.1246,  0.0713],\n",
       "        [ 0.1521,  0.0528,  0.5368,  0.2694,  0.1580,  0.0141,  0.0887,  0.1934,\n",
       "          0.2060, -0.0743, -0.0123,  0.1717,  0.0499,  0.1655,  0.0533,  1.0000,\n",
       "          0.0932, -0.0769],\n",
       "        [ 0.2081,  0.0351,  0.0079,  0.2068,  0.2352,  0.1195,  0.1745,  0.2230,\n",
       "          0.0884,  0.0399,  0.1288,  0.1394,  0.1086,  0.1231,  0.1246,  0.0932,\n",
       "          1.0000,  0.1289],\n",
       "        [ 0.2013,  0.0866,  0.0849,  0.1540,  0.1408,  0.0203,  0.2684,  0.1526,\n",
       "         -0.0106,  0.3723,  0.1918,  0.0583,  0.1404,  0.0543,  0.0713, -0.0769,\n",
       "          0.1289,  1.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs @ embs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.index('Dutch'), langs.index('German')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0714)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embs @ embs.T)[langs.index('Dutch'), langs.index('German')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = embs @ embs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  0.2107,  0.0737,  0.2169,  0.1690,  0.0574,  0.1231,  0.0924,\n",
       "         0.0648,  0.0909,  0.1546,  0.2940,  0.1050,  0.5703,  0.1036,  0.1521,\n",
       "         0.2081,  0.2013,  0.2107,  1.0000,  0.0932,  0.1489,  0.2433, -0.0682,\n",
       "         0.1810,  0.0422,  0.0322,  0.2441,  0.0943,  0.1621,  0.1060, -0.0451,\n",
       "         0.0982,  0.0528,  0.0351,  0.0866,  0.0737,  0.0932,  1.0000,  0.1454,\n",
       "         0.1286,  0.0507,  0.0611,  0.1267,  0.1156,  0.0236, -0.0714,  0.0739,\n",
       "         0.0321, -0.0377,  0.1375,  0.5368,  0.0079,  0.0849,  0.2169,  0.1489,\n",
       "         0.1454,  1.0000,  0.2834,  0.0480,  0.5383,  0.4475,  0.2274,  0.2292,\n",
       "         0.1214,  0.4268,  0.2903,  0.0963,  0.2392,  0.2694,  0.2068,  0.1540,\n",
       "         0.1690,  0.2433,  0.1286,  0.2834,  1.0000,  0.0512,  0.2824,  0.2721,\n",
       "         0.2256,  0.1379,  0.2641,  0.3470,  0.1003,  0.2416,  0.3414,  0.1580,\n",
       "         0.2352,  0.1408,  0.0574, -0.0682,  0.0507,  0.0480,  0.0512,  1.0000,\n",
       "         0.1121,  0.1166,  0.1957, -0.0904, -0.0044,  0.0207, -0.0518, -0.0565,\n",
       "         0.0585,  0.0141,  0.1195,  0.0203,  0.1231,  0.1810,  0.0611,  0.5383,\n",
       "         0.2824,  0.1121,  1.0000,  0.2391,  0.2198,  0.2402,  0.1826,  0.1989,\n",
       "         0.0689,  0.0282,  0.1149,  0.0887,  0.1745,  0.2684,  0.0924,  0.0422,\n",
       "         0.1267,  0.4475,  0.2721,  0.1166,  0.2391,  1.0000,  0.2115,  0.0503,\n",
       "         0.1059,  0.3017,  0.1925,  0.1873,  0.1276,  0.1934,  0.2230,  0.1526,\n",
       "         0.0648,  0.0322,  0.1156,  0.2274,  0.2256,  0.1957,  0.2198,  0.2115,\n",
       "         1.0000,  0.0120,  0.0695,  0.1998,  0.0304,  0.1309,  0.1863,  0.2060,\n",
       "         0.0884, -0.0106,  0.0909,  0.2441,  0.0236,  0.2292,  0.1379, -0.0904,\n",
       "         0.2402,  0.0503,  0.0120,  1.0000,  0.0622,  0.1258,  0.1236,  0.0046,\n",
       "         0.0385, -0.0743,  0.0399,  0.3723,  0.1546,  0.0943, -0.0714,  0.1214,\n",
       "         0.2641, -0.0044,  0.1826,  0.1059,  0.0695,  0.0622,  1.0000,  0.0590,\n",
       "         0.1568,  0.1089,  0.0530, -0.0123,  0.1288,  0.1918,  0.2940,  0.1621,\n",
       "         0.0739,  0.4268,  0.3470,  0.0207,  0.1989,  0.3017,  0.1998,  0.1258,\n",
       "         0.0590,  1.0000,  0.2323,  0.2607,  0.1142,  0.1717,  0.1394,  0.0583,\n",
       "         0.1050,  0.1060,  0.0321,  0.2903,  0.1003, -0.0518,  0.0689,  0.1925,\n",
       "         0.0304,  0.1236,  0.1568,  0.2323,  1.0000,  0.0299,  0.0996,  0.0499,\n",
       "         0.1086,  0.1404,  0.5703, -0.0451, -0.0377,  0.0963,  0.2416, -0.0565,\n",
       "         0.0282,  0.1873,  0.1309,  0.0046,  0.1089,  0.2607,  0.0299,  1.0000,\n",
       "         0.0020,  0.1655,  0.1231,  0.0543,  0.1036,  0.0982,  0.1375,  0.2392,\n",
       "         0.3414,  0.0585,  0.1149,  0.1276,  0.1863,  0.0385,  0.0530,  0.1142,\n",
       "         0.0996,  0.0020,  1.0000,  0.0533,  0.1246,  0.0713,  0.1521,  0.0528,\n",
       "         0.5368,  0.2694,  0.1580,  0.0141,  0.0887,  0.1934,  0.2060, -0.0743,\n",
       "        -0.0123,  0.1717,  0.0499,  0.1655,  0.0533,  1.0000,  0.0932, -0.0769,\n",
       "         0.2081,  0.0351,  0.0079,  0.2068,  0.2352,  0.1195,  0.1745,  0.2230,\n",
       "         0.0884,  0.0399,  0.1288,  0.1394,  0.1086,  0.1231,  0.1246,  0.0932,\n",
       "         1.0000,  0.1289,  0.2013,  0.0866,  0.0849,  0.1540,  0.1408,  0.0203,\n",
       "         0.2684,  0.1526, -0.0106,  0.3723,  0.1918,  0.0583,  0.1404,  0.0543,\n",
       "         0.0713, -0.0769,  0.1289,  1.0000])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for divmod(): 'Tensor' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/oadams/code/sigtyp2023/Untitled.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oadams/code/sigtyp2023/Untitled.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m flattened_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margsort(sims\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oadams/code/sigtyp2023/Untitled.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Convert the flattened indices to 2D indices\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oadams/code/sigtyp2023/Untitled.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m row_indices, col_indices \u001b[39m=\u001b[39m \u001b[39mdivmod\u001b[39;49m(flattened_indices, sims\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for divmod(): 'Tensor' and 'int'"
     ]
    }
   ],
   "source": [
    "# Flatten the matrix to a 1D tensor and get indices that would sort it\n",
    "flattened_indices = torch.argsort(sims.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(209)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.argmax(dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 18])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "argsort: You passed a dimname (string) to this op in place of a dimension index but it does not yet support this behavior. Please pass a dimension index to work around this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/oadams/code/sigtyp2023/Untitled.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oadams/code/sigtyp2023/Untitled.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sims\u001b[39m.\u001b[39;49margsort(dim\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: argsort: You passed a dimname (string) to this op in place of a dimension index but it does not yet support this behavior. Please pass a dimension index to work around this."
     ]
    }
   ],
   "source": [
    "sims.argsort(dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the matrix to perform sorting\n",
    "flattened_matrix = sims.view(-1)  # Flatten the 2D matrix into a 1D tensor\n",
    "sorted_indices = torch.argsort(flattened_matrix, dim=0)\n",
    "\n",
    "# Retrieve row and column indices based on sorted indices\n",
    "row_indices = sorted_indices // sims.shape[1]\n",
    "col_indices = sorted_indices % sims.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czech Japanese tensor(-0.0904)\n",
      "Frisian Hakha_Chin tensor(-0.0769)\n",
      "Japanese Frisian tensor(-0.0743)\n",
      "Dutch German tensor(-0.0714)\n",
      "Dhivehi Czech tensor(-0.0682)\n",
      "Czech Tatar tensor(-0.0565)\n",
      "Czech Chinese_Taiwan tensor(-0.0518)\n",
      "Dhivehi Tatar tensor(-0.0451)\n",
      "Dutch Tatar tensor(-0.0377)\n",
      "German Frisian tensor(-0.0123)\n",
      "Latvian Hakha_Chin tensor(-0.0106)\n",
      "Czech German tensor(-0.0044)\n",
      "Tatar Kinyarwanda tensor(0.0020)\n",
      "Japanese Tatar tensor(0.0046)\n",
      "Dutch Welsh tensor(0.0079)\n",
      "Latvian Japanese tensor(0.0120)\n",
      "Czech Frisian tensor(0.0141)\n",
      "Czech Hakha_Chin tensor(0.0203)\n",
      "Czech Estonian tensor(0.0207)\n",
      "Dutch Japanese tensor(0.0236)\n",
      "Esperanto Tatar tensor(0.0282)\n",
      "Chinese_Taiwan Tatar tensor(0.0299)\n",
      "Latvian Chinese_Taiwan tensor(0.0304)\n",
      "Dutch Chinese_Taiwan tensor(0.0321)\n",
      "Dhivehi Latvian tensor(0.0322)\n",
      "Dhivehi Welsh tensor(0.0351)\n",
      "Japanese Kinyarwanda tensor(0.0385)\n",
      "Japanese Welsh tensor(0.0399)\n",
      "Dhivehi Catalan tensor(0.0422)\n",
      "Interlingua Czech tensor(0.0480)\n",
      "Chinese_Taiwan Frisian tensor(0.0499)\n",
      "Catalan Japanese tensor(0.0503)\n",
      "Dutch Czech tensor(0.0507)\n",
      "Breton Czech tensor(0.0512)\n",
      "Dhivehi Frisian tensor(0.0528)\n",
      "German Kinyarwanda tensor(0.0530)\n",
      "Kinyarwanda Frisian tensor(0.0533)\n",
      "Tatar Hakha_Chin tensor(0.0543)\n",
      "Sakha Czech tensor(0.0574)\n",
      "Estonian Hakha_Chin tensor(0.0583)\n",
      "Czech Kinyarwanda tensor(0.0585)\n",
      "German Estonian tensor(0.0590)\n",
      "Dutch Esperanto tensor(0.0611)\n",
      "Japanese German tensor(0.0622)\n",
      "Sakha Latvian tensor(0.0648)\n",
      "Esperanto Chinese_Taiwan tensor(0.0689)\n",
      "Latvian German tensor(0.0695)\n",
      "Kinyarwanda Hakha_Chin tensor(0.0713)\n",
      "Sakha Dutch tensor(0.0737)\n",
      "Dutch Estonian tensor(0.0739)\n",
      "Dutch Hakha_Chin tensor(0.0849)\n",
      "Dhivehi Hakha_Chin tensor(0.0866)\n",
      "Latvian Welsh tensor(0.0884)\n",
      "Esperanto Frisian tensor(0.0887)\n",
      "Sakha Japanese tensor(0.0909)\n",
      "Sakha Catalan tensor(0.0924)\n",
      "Dhivehi Dutch tensor(0.0932)\n",
      "Frisian Welsh tensor(0.0932)\n",
      "Dhivehi German tensor(0.0943)\n",
      "Interlingua Tatar tensor(0.0963)\n",
      "Dhivehi Kinyarwanda tensor(0.0982)\n",
      "Chinese_Taiwan Kinyarwanda tensor(0.0996)\n",
      "Breton Chinese_Taiwan tensor(0.1003)\n",
      "Sakha Kinyarwanda tensor(0.1036)\n",
      "Sakha Chinese_Taiwan tensor(0.1050)\n",
      "Catalan German tensor(0.1059)\n",
      "Dhivehi Chinese_Taiwan tensor(0.1060)\n",
      "Chinese_Taiwan Welsh tensor(0.1086)\n",
      "German Tatar tensor(0.1089)\n",
      "Czech Esperanto tensor(0.1121)\n",
      "Estonian Kinyarwanda tensor(0.1142)\n",
      "Esperanto Kinyarwanda tensor(0.1149)\n",
      "Dutch Latvian tensor(0.1156)\n",
      "Czech Catalan tensor(0.1166)\n",
      "Czech Welsh tensor(0.1195)\n",
      "Interlingua German tensor(0.1214)\n",
      "Tatar Welsh tensor(0.1231)\n",
      "Sakha Esperanto tensor(0.1231)\n",
      "Japanese Chinese_Taiwan tensor(0.1236)\n",
      "Kinyarwanda Welsh tensor(0.1246)\n",
      "Japanese Estonian tensor(0.1258)\n",
      "Dutch Catalan tensor(0.1267)\n",
      "Catalan Kinyarwanda tensor(0.1276)\n",
      "Dutch Breton tensor(0.1286)\n",
      "German Welsh tensor(0.1288)\n",
      "Welsh Hakha_Chin tensor(0.1289)\n",
      "Latvian Tatar tensor(0.1309)\n",
      "Dutch Kinyarwanda tensor(0.1375)\n",
      "Breton Japanese tensor(0.1379)\n",
      "Estonian Welsh tensor(0.1394)\n",
      "Chinese_Taiwan Hakha_Chin tensor(0.1404)\n",
      "Breton Hakha_Chin tensor(0.1408)\n",
      "Dutch Interlingua tensor(0.1454)\n",
      "Dhivehi Interlingua tensor(0.1489)\n",
      "Sakha Frisian tensor(0.1521)\n",
      "Catalan Hakha_Chin tensor(0.1526)\n",
      "Interlingua Hakha_Chin tensor(0.1540)\n",
      "Sakha German tensor(0.1546)\n",
      "German Chinese_Taiwan tensor(0.1568)\n",
      "Breton Frisian tensor(0.1580)\n",
      "Dhivehi Estonian tensor(0.1621)\n",
      "Tatar Frisian tensor(0.1655)\n",
      "Sakha Breton tensor(0.1690)\n",
      "Estonian Frisian tensor(0.1717)\n",
      "Esperanto Welsh tensor(0.1745)\n",
      "Dhivehi Esperanto tensor(0.1810)\n",
      "Esperanto German tensor(0.1826)\n",
      "Latvian Kinyarwanda tensor(0.1863)\n",
      "Catalan Tatar tensor(0.1873)\n",
      "German Hakha_Chin tensor(0.1918)\n",
      "Catalan Chinese_Taiwan tensor(0.1925)\n",
      "Catalan Frisian tensor(0.1934)\n",
      "Czech Latvian tensor(0.1957)\n",
      "Esperanto Estonian tensor(0.1989)\n",
      "Latvian Estonian tensor(0.1998)\n",
      "Sakha Hakha_Chin tensor(0.2013)\n",
      "Latvian Frisian tensor(0.2060)\n",
      "Interlingua Welsh tensor(0.2068)\n",
      "Sakha Welsh tensor(0.2081)\n",
      "Sakha Dhivehi tensor(0.2107)\n",
      "Catalan Latvian tensor(0.2115)\n",
      "Sakha Interlingua tensor(0.2169)\n",
      "Esperanto Latvian tensor(0.2198)\n",
      "Catalan Welsh tensor(0.2230)\n",
      "Breton Latvian tensor(0.2256)\n",
      "Interlingua Latvian tensor(0.2274)\n",
      "Interlingua Japanese tensor(0.2292)\n",
      "Estonian Chinese_Taiwan tensor(0.2323)\n",
      "Breton Welsh tensor(0.2352)\n",
      "Esperanto Catalan tensor(0.2391)\n",
      "Interlingua Kinyarwanda tensor(0.2392)\n",
      "Esperanto Japanese tensor(0.2402)\n",
      "Breton Tatar tensor(0.2416)\n",
      "Dhivehi Breton tensor(0.2433)\n",
      "Dhivehi Japanese tensor(0.2441)\n",
      "Estonian Tatar tensor(0.2607)\n",
      "Breton German tensor(0.2641)\n",
      "Esperanto Hakha_Chin tensor(0.2684)\n",
      "Interlingua Frisian tensor(0.2694)\n",
      "Breton Catalan tensor(0.2721)\n",
      "Breton Esperanto tensor(0.2824)\n",
      "Interlingua Breton tensor(0.2834)\n",
      "Interlingua Chinese_Taiwan tensor(0.2903)\n",
      "Sakha Estonian tensor(0.2940)\n",
      "Catalan Estonian tensor(0.3017)\n",
      "Breton Kinyarwanda tensor(0.3414)\n",
      "Breton Estonian tensor(0.3470)\n",
      "Japanese Hakha_Chin tensor(0.3723)\n",
      "Interlingua Estonian tensor(0.4268)\n",
      "Interlingua Catalan tensor(0.4475)\n",
      "Dutch Frisian tensor(0.5368)\n",
      "Interlingua Esperanto tensor(0.5383)\n",
      "Sakha Tatar tensor(0.5703)\n"
     ]
    }
   ],
   "source": [
    "for a, b in list(zip(row_indices, col_indices)):\n",
    "    if a >= b:\n",
    "        continue\n",
    "    print(langs[a.item()], langs[b.item()], sims[a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
